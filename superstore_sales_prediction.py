# -*- coding: utf-8 -*-
"""Superstore_Sales_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/sahilkumar0511/Superstore_Sales_Prediction/blob/main/Superstore_Sales_Prediction.ipynb
"""

import numpy as np
import pandas as pd

df = pd.read_csv('Superstore.csv', encoding = 'windows-1252')
df

df.info()

df = df.drop(['Row ID', 'Country', 'Product ID', 'Product Name', 'Order ID', 'Customer Name','Customer ID'], axis = 1)
df

df['State'].unique()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

data=df.corr()
sns.heatmap(data,annot=True,cmap='viridis')
# %matplotlib inline

df.groupby('Region').mean()

df.groupby('Ship Mode').mean()

df.groupby('Segment').mean()

df.groupby('Category').mean()

def encode_dates(df, column):
    df = df.copy()
    df[column] = pd.to_datetime(df[column])
    df[column + '_year'] = df[column].apply(lambda x: x.year)
    df = df.drop(column, axis=1)
    return df

def onehot_encode(df, column):
    df = df.copy()
    dummies = pd.get_dummies(df[column], prefix=column)
    df = pd.concat([df, dummies], axis=1)
    df = df.drop(column, axis=1)
    return df

df = encode_dates(df, column='Order Date')

df = df.drop(['Ship Mode', 'Segment', 'City', 'State', 'Postal Code', 'Region','Sub-Category', 'Discount', 'Order Date_year', 'Ship Date'], axis = 1)
df

df.columns

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df.Category = le.fit_transform(df.Category)
df

#for column in ['Category']:
  #df = onehot_encode(df, column=column)

df

df.Profit.mean()

X = df.drop('Sales', axis=1)
Y = df['Sales']

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size=0.2, random_state=4)
X_train.shape

X_train.describe()

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_train = pd.DataFrame(scaler.transform(X_train), columns= X.columns)
X_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)

X_train.describe()

import tensorflow as tf
from keras.layers import Dense
from keras.models import Sequential
inputs = tf.keras.Input(shape =(X_train.shape[1],))
x = tf.keras.layers.Dense(64, activation='relu')(inputs)
x = tf.keras.layers.Dense(64, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
outputs = tf.keras.layers.Dense(1, activation='linear')(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)
print(model.summary())

model.compile(optimizer='adam', loss='mse')
history = model.fit(
    X_train,
    Y_train,
    validation_data=(X_test,Y_test),
    batch_size=32,
    epochs=100,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        ),
        tf.keras.callbacks.ReduceLROnPlateau()
    ]
)

test_loss = model.evaluate(X_test,Y_test, verbose=0)
print("Test Loss: {:.5f}".format(test_loss))

from sklearn.metrics import r2_score
y_pred = np.squeeze(model.predict(X_test))
test_r2 = r2_score(Y_test, y_pred)
print("Test R^2 Score: {:.5f}".format(test_r2))

model.predict([[28,3,0]])

